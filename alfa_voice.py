import queue, json, requests, sounddevice as sd
from vosk import Model, KaldiRecognizer
import pyttsx3

# ≈öcie≈ºka do modelu VOSK (upewnij siƒô, ≈ºe folder istnieje)
VOSK_PATH = "vosk-model-small-pl-0.22"
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

# Inicjalizacja Vosk i kolejek audio
model = Model(VOSK_PATH)
rec = KaldiRecognizer(model, 16000)
audio_queue = queue.Queue()

# G≈Ços Aria (offline)
def speak(text):
    engine = pyttsx3.init()
    engine.setProperty('rate', 170)
    engine.setProperty('volume', 0.9)
    voices = engine.getProperty('voices')
    for v in voices:
        if "female" in v.name.lower():
            engine.setProperty('voice', v.id)
            break
    engine.say(text)
    engine.runAndWait()

# Odpowied≈∫ z Ollamy
def ask_ollama(prompt):
    try:
        payload = {"model": "mistral:7b", "prompt": prompt}
        response = requests.post(OLLAMA_URL, json=payload, timeout=120)
        data = response.json()
        reply = data.get("response", "").strip()
        print(f"\nü§ñ OLLAMA: {reply}")
        speak(reply)
    except Exception as e:
        print("‚ö†Ô∏è B≈ÇƒÖd komunikacji z OllamƒÖ:", e)

# Callback audio (zbiera dane z mikrofonu)
def callback(indata, frames, time, status):
    audio_queue.put(bytes(indata))

# G≈Ç√≥wna pƒôtla nas≈Çuchiwania
def listen():
    print("üéôÔ∏è Powiedz co≈õ... (CTRL+C aby zako≈Ñczyƒá)")
    with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16', channels=1, callback=callback):
        while True:
            data = audio_queue.get()
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "")
                if text:
                    print(f"\nüó£Ô∏è Ty: {text}")
                    ask_ollama(text)

if __name__ == "__main__":
    try:
        speak("System ALFA Voice uruchomiony.")
        listen()
    except KeyboardInterrupt:
        print("\nZako≈Ñczono nas≈Çuchiwanie.")
        speak("Do zobaczenia.")
import queue, json, requests, sounddevice as sd
from vosk import Model, KaldiRecognizer
import pyttsx3

# ≈öcie≈ºka do modelu VOSK (upewnij siƒô, ≈ºe folder istnieje)
VOSK_PATH = "vosk-model-small-pl-0.22"
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

# Inicjalizacja Vosk i kolejek audio
model = Model(VOSK_PATH)
rec = KaldiRecognizer(model, 16000)
audio_queue = queue.Queue()

# G≈Ços Aria (offline)
def speak(text):
    engine = pyttsx3.init()
    engine.setProperty('rate', 170)
    engine.setProperty('volume', 0.9)
    voices = engine.getProperty('voices')
    for v in voices:
        if "female" in v.name.lower():
            engine.setProperty('voice', v.id)
            break
    engine.say(text)
    engine.runAndWait()

# Odpowied≈∫ z Ollamy
def ask_ollama(prompt):
    try:
        payload = {"model": "mistral:7b", "prompt": prompt}
        response = requests.post(OLLAMA_URL, json=payload, timeout=120)
        data = response.json()
        reply = data.get("response", "").strip()
        print(f"\nü§ñ OLLAMA: {reply}")
        speak(reply)
    except Exception as e:
        print("‚ö†Ô∏è B≈ÇƒÖd komunikacji z OllamƒÖ:", e)

# Callback audio (zbiera dane z mikrofonu)
def callback(indata, frames, time, status):
    audio_queue.put(bytes(indata))

# G≈Ç√≥wna pƒôtla nas≈Çuchiwania
def listen():
    print("üéôÔ∏è Powiedz co≈õ... (CTRL+C aby zako≈Ñczyƒá)")
    with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16', channels=1, callback=callback):
        while True:
            data = audio_queue.get()
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "")
                if text:
                    print(f"\nüó£Ô∏è Ty: {text}")
                    ask_ollama(text)

if __name__ == "__main__":
    try:
        speak("System ALFA Voice uruchomiony.")
        listen()
    except KeyboardInterrupt:
        print("\nZako≈Ñczono nas≈Çuchiwanie.")
        speak("Do zobaczenia.")
import speech_recognition as sr
import requests
import pyttsx3

OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

r = sr.Recognizer()
engine = pyttsx3.init()
engine.setProperty('rate', 170)
engine.setProperty('volume', 0.9)

print("üéôÔ∏è ALFA Voice (Windows) aktywny ‚Äì m√≥w po polsku.")

while True:
    with sr.Microphone() as source:
        print("\nS≈Çucham...")
        audio = r.listen(source)
    try:
        text = r.recognize_google(audio, language="pl-PL")
        print("üó£Ô∏è Ty:", text)

        data = {"model": "mistral:7b", "prompt": text}
        reply = requests.post(OLLAMA_URL, json=data, timeout=120).json()["response"]
        print("ü§ñ ALFA:", reply)

        engine.say(reply)
        engine.runAndWait()

    except sr.UnknownValueError:
        print("‚ùì Nie zrozumia≈Çem ‚Äì powt√≥rz.")
    except Exception as e:
        print("‚ö†Ô∏è B≈ÇƒÖd:", e)
